{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad034d-d71b-4f3d-a0c7-75c2d6cf5b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88025c46-a078-4d3f-b403-ca4cb6a189ca",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#2. specify parameters\n",
    "pipeline_params={\n",
    "}\n",
    "step_params={\n",
    "}\n",
    "substep_params={\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067c0a4-3e3e-46f9-8b49-d905d1a1bf96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#3 define substep interface\n",
    "from sinara.substep import NotebookSubstep, default_param_values, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params, **default_param_values(\"params/step_params.json\"))\n",
    "\n",
    "substep.interface(\n",
    "    tmp_outputs =\n",
    "    [\n",
    "        { ENTITY_NAME: \"cache_data\" },\n",
    "        { ENTITY_NAME: \"cache_config\" }\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b79ca-f8ac-4ee2-81c2-caa79f78cab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#4 write outputs\n",
    "tmp_outputs = substep.tmp_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4a572-4573-4ead-8912-a3560e53db86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#5 run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f8139-6fc4-4a82-8afb-734c2b3414c5",
   "metadata": {},
   "source": [
    "#### Dataset description:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444815b4-70a9-40e1-8471-5d006182e7d6",
   "metadata": {},
   "source": [
    "The COCO (Common Objects in Context) dataset is a large-scale image recognition dataset for object detection, segmentation, and captioning tasks. It contains over 330,000 images, each annotated with 80 object categories and 5 captions describing the scene. The COCO dataset is widely used in computer vision research and has been used to train and evaluate many state-of-the-art object detection and segmentation models.\n",
    "\n",
    "The dataset has two main parts: the images and their annotations.\n",
    "\n",
    "The images are organized into a hierarchy of directories, with the top-level directory containing subdirectories for the train, validation, and test sets.\n",
    "The annotations are provided in JSON format, with each file corresponding to a single image.\n",
    "Each annotation in the dataset includes the following information:\n",
    "\n",
    "Image file name\n",
    "Image size (width and height)\n",
    "List of objects with the following information: Object class (e.g., \"person,\" \"car\"); Bounding box coordinates (x, y, width, height); Segmentation mask (polygon or RLE format); Keypoints and their positions (if available)\n",
    "Five captions describing the scene\n",
    "The COCO dataset also provides additional information, such as image super categories, license, and coco-stuff (pixel-wise annotations for stuff classes in addition to 80 object classes).\n",
    "\n",
    "MS COCO offers various types of annotations,\n",
    "\n",
    "Object detection with bounding box coordinates and full segmentation masks for 80 different objects\n",
    "Stuff image segmentation with pixel maps displaying 91 amorphous background areas\n",
    "Panoptic segmentation identifies items in images based on 80 \"things\" and 91 \"stuff\" categories\n",
    "Dense pose with over 39,000 photos featuring over 56,000 tagged persons with a mapping between pixels and a template 3D model and natural language descriptions for each image\n",
    "Keypoint annotations for over 250,000 persons annotated with key points such as the right eye, nose, and left hip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398c9d8-2ec6-42f6-ad0f-0a929b973062",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset load process    \n",
    "Download dataset from the internet storage    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d224e39-4028-4ce9-bde5-5dcbf3d626b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#5 load dataset \n",
    "data_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "annot_url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b806b-1318-4483-b4d5-9bc320ef8346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{tmp_outputs.cache_data=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba533bb4-f7b6-4db6-8a5a-bcec13810dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "os.makedirs(tmp_outputs.cache_data)\n",
    "os.makedirs(tmp_outputs.cache_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd7dc2-f644-4235-a5ba-0c21c06ca7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget {data_url} -O {osp.join(tmp_outputs.cache_data, osp.basename(data_url))}\n",
    "!wget {annot_url} -O {osp.join(tmp_outputs.cache_data, osp.basename(annot_url))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b60225-2226-470b-b627-339a93a2b704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#6 unzip dataset\n",
    "!unzip -q {osp.join(tmp_outputs.cache_data, osp.basename(data_url))} -d {tmp_outputs.cache_data}\n",
    "!unzip -q {osp.join(tmp_outputs.cache_data, osp.basename(annot_url))} -d {tmp_outputs.cache_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118211c-62a1-4dec-a5c1-02db47de136a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls {tmp_outputs.cache_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d699a7c-a886-42b2-a69c-385547a61428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls {osp.join(tmp_outputs.cache_data, \"annotations\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa243b4-ec85-4950-94f5-6c08898e53a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#7 stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92434180-0885-4a11-b5c4-f746e38dc935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
