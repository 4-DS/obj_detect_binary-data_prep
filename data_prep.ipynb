{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a281c4-d0fd-40c4-9849-91d0f1669678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebf8f4-cdbe-4ace-9fa5-e0300e2a1fc5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "pipeline_params={\n",
    "}\n",
    "step_params={\n",
    "}\n",
    "substep_params={\n",
    "    \"FILTER_EMPTY_GT\"    : False,\n",
    "    \"MIN_OBJECT_SIZE\"    : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6426737-251e-46c2-9fc4-66efd6389921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, default_param_values, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params, **default_param_values(\"params/step_params.json\"))\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [\n",
    "        {STEP_NAME: \"data_load\", ENTITY_NAME: \"images\"}, # images from data_load step\n",
    "        {STEP_NAME: \"data_load\", ENTITY_NAME: \"annotations\"} # coco annotations from data_load step\n",
    "    ],\n",
    "    tmp_entities =\n",
    "    [    \n",
    "        { ENTITY_NAME: \"images\"}, # extracted temporary images from Sinara Archive\n",
    "        { ENTITY_NAME: \"annotations\"}, # extracted temporary annotations from Sinara Archive\n",
    "        { ENTITY_NAME: \"train_data\"}, # temporary coco dataset for object detector train\n",
    "        { ENTITY_NAME: \"eval_data\"}, # temporary coco dataset for object detector eval\n",
    "        { ENTITY_NAME: \"test_data\"}, # temporary coco dataset for object detector test\n",
    "        #{ ENTITY_NAME: \"dataset_config\"} # information about all datasets and classes used for pipeline\n",
    "    ],\n",
    "    outputs = \n",
    "    [\n",
    "        { ENTITY_NAME: \"train_data\"}, # coco dataset archived for object detector train\n",
    "        { ENTITY_NAME: \"eval_data\"}, # coco dataset archived  for object detector eval\n",
    "        { ENTITY_NAME: \"test_data\"}, # coco dataset archived  for object detector test\n",
    "        #{ ENTITY_NAME: \"dataset_config\"} # information about all datasets and classes used for pipeline\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76aa12-771f-4a41-a999-599396e10cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a28711-f22f-40c9-b0fc-02187c04b559",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading dataset and annotation files (from the previous component data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16757091-17a6-4ba3-b922-d0a5528ae21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sinara.store import SinaraStore\n",
    "\n",
    "inputs = substep.inputs(step_name = \"data_load\")\n",
    "tmp_entities = substep.tmp_entities()\n",
    "\n",
    "# copy data from previos step to tmp_entities\n",
    "SinaraStore.dearchive_store_files_to_tmp(store_path=inputs.images, tmp_dir=tmp_entities.images)\n",
    "SinaraStore.dearchive_store_files_to_tmp(store_path=inputs.annotations, tmp_dir=tmp_entities.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237b0fb-1bb0-48f8-9390-9e77304c7ec6",
   "metadata": {},
   "source": [
    "### Selecting object categories from general annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e75e71-5c24-49e9-90f0-7caaddbd44c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.coco import join_coco_files, load as load_coco\n",
    "from utils.coco import preview_coco_file\n",
    "from utils.coco import show_item\n",
    "from utils.coco import get_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "# Load annotation from json\n",
    "coco_annotation = load_coco(osp.join(tmp_entities.annotations, \"instances_val2017.json\"))\n",
    "\n",
    "# Selection of object types for subsequent neural network training\n",
    "select_object_names = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\"]\n",
    "# CLASSES = select_object_names\n",
    "select_categories= [cat_info.copy() for cat_info in coco_annotation[\"categories\"] if cat_info[\"name\"] in select_object_names]\n",
    "for new_id, cat_info in enumerate(select_categories, 1):\n",
    "    cat_info[\"old_id\"] = cat_info[\"id\"]\n",
    "    cat_info[\"id\"] = new_id \n",
    "    \n",
    "# Select annotation object by select_categories\n",
    "reid_categories_ids = {cat_info[\"old_id\"]: cat_info[\"id\"] for cat_info in select_categories} # reidentification categories\n",
    "\n",
    "new_coco_annotations = []\n",
    "for annot in coco_annotation[\"annotations\"]:\n",
    "    new_annot = annot.copy()\n",
    "    category_id = new_annot[\"category_id\"]\n",
    "    if category_id in reid_categories_ids.keys():\n",
    "        new_annot[\"category_id\"] = reid_categories_ids[category_id]\n",
    "        new_coco_annotations.append(new_annot)\n",
    "        \n",
    "# apply new annotation\n",
    "coco_annotation[\"categories\"] = select_categories.copy()\n",
    "coco_annotation[\"annotations\"] = new_coco_annotations.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae3ce7-8d97-43e7-80a7-ae4c0ba94540",
   "metadata": {},
   "source": [
    "### Split Dataset to Train, Valid and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632979d5-58ff-429f-bae7-c644c1dcc811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split to train, valid and test parts\n",
    "train_coco_images, val_coco_images = train_test_split(coco_annotation[\"images\"], test_size=0.33, random_state=42)\n",
    "val_coco_images, test_coco_images = train_test_split(val_coco_images.copy(), test_size=0.1, random_state=42)\n",
    "\n",
    "train_images_ids = [img_info[\"id\"] for img_info in train_coco_images]\n",
    "val_images_ids = [img_info[\"id\"] for img_info in val_coco_images]\n",
    "test_images_ids = [img_info[\"id\"] for img_info in test_coco_images]\n",
    "\n",
    "train_images_names = [img_info[\"file_name\"] for img_info in train_coco_images]\n",
    "val_images_names = [img_info[\"file_name\"] for img_info in val_coco_images]\n",
    "test_images_names = [img_info[\"file_name\"] for img_info in test_coco_images]\n",
    "\n",
    "train_coco_annotations = [annot.copy() for annot in coco_annotation[\"annotations\"] if annot[\"image_id\"] in train_images_ids]\n",
    "val_coco_annotations = [annot.copy() for annot in coco_annotation[\"annotations\"] if annot[\"image_id\"] in val_images_ids]\n",
    "test_coco_annotations = [annot.copy() for annot in coco_annotation[\"annotations\"] if annot[\"image_id\"] in test_images_ids]\n",
    "\n",
    "\n",
    "# create coco annotation for train dataset\n",
    "train_coco = coco_annotation.copy()\n",
    "train_coco[\"images\"] = train_coco_images\n",
    "train_coco[\"annotations\"] = train_coco_annotations\n",
    "\n",
    "# create coco annotation for train dataset\n",
    "val_coco = coco_annotation.copy()\n",
    "val_coco[\"images\"] = val_coco_images\n",
    "val_coco[\"annotations\"] = val_coco_annotations\n",
    "\n",
    "# create coco annotation for train dataset\n",
    "test_coco = coco_annotation.copy()\n",
    "test_coco[\"images\"] = test_coco_images\n",
    "test_coco[\"annotations\"] = test_coco_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da8ec3-5a2b-41c4-8d99-cfe2934d32d1",
   "metadata": {},
   "source": [
    "### Review Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08899895-6ae5-414d-a956-aca9f272ffb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preview examples of data from train, valid and test dataset\n",
    "preview_coco_file(train_coco, img_folder=tmp_entities.images, count=2)\n",
    "preview_coco_file(val_coco, img_folder=tmp_entities.images, count=2)\n",
    "preview_coco_file(test_coco, img_folder=tmp_entities.images, count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902fccd-ae38-466b-8f9c-31df58018690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overview of the distribution of labeled data (detection)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "areas  = []\n",
    "counts = []\n",
    "categories = []\n",
    "categories_annotation = []\n",
    "\n",
    "anns = coco_annotation.get('annotations', [])\n",
    "for image in coco_annotation.get('images', []):\n",
    "    image_anns = [ann for ann in anns if ann['image_id'] == image['id']]\n",
    "    counts.append(len(image_anns))\n",
    "    \n",
    "    for ann in image_anns:\n",
    "        areas.append(ann.get('area'))\n",
    "        categories.append(ann.get('category_id'))\n",
    "    \n",
    "    categories_annotation += coco_annotation['categories']\n",
    "           \n",
    "counts = np.array(counts)\n",
    "areas  = np.array(areas)\n",
    "\n",
    "#overview of the distribution of detection marking areas throughout the entire dataset\n",
    "fig = px.histogram(areas, title='Area of objects at dataset images')\n",
    "fig.layout.yaxis.title = 'Objects count'\n",
    "fig.layout.xaxis.title = 'Area'\n",
    "fig.show()\n",
    "\n",
    "#erview of the distribution of marked objects throughout the entire dataset\n",
    "fig = px.histogram(counts, title='Objects count at dataset images')\n",
    "fig.layout.yaxis.title = 'Objects count'\n",
    "fig.layout.xaxis.title = 'Images count'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13221d-3524-497e-9761-fac7b0b4419f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save train, validation and test datasets to parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203dbcc-0356-476c-8e0e-28d37feb1dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save images for train, validation and test datasets to tmp_entities\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_dataset_images(_coco_data, source_img_folder:str, dest_img_folder: str):\n",
    "    pack = []\n",
    "    for img_info in tqdm(_coco_data[\"images\"]):\n",
    "        source_file_name = osp.join(source_img_folder, img_info[\"file_name\"])\n",
    "        dest_file_name = osp.join(dest_img_folder, img_info[\"file_name\"])\n",
    "        shutil.copyfile(source_file_name, dest_file_name)\n",
    "        \n",
    "prepare_dataset_images(train_coco, source_img_folder=tmp_entities.images, dest_img_folder=tmp_entities.train_data)\n",
    "prepare_dataset_images(val_coco, source_img_folder=tmp_entities.images, dest_img_folder=tmp_entities.eval_data)\n",
    "prepare_dataset_images(test_coco, source_img_folder=tmp_entities.images, dest_img_folder=tmp_entities.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e5954-40b3-44f3-b239-aed65260c2a5",
   "metadata": {},
   "source": [
    "### Save train, validation and test annotations to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23e4c6-4ee0-47c1-8bbb-ab5fe8cb5f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save annotations for every datasets\n",
    "import json\n",
    "train_annotation_path = osp.join(tmp_entities.train_data, \"train_coco_annotations.json\")\n",
    "val_annotation_path = osp.join(tmp_entities.eval_data, \"val_coco_annotations.json\")\n",
    "test_annotation_path = osp.join(tmp_entities.test_data, \"test_coco_annotations.json\")\n",
    "\n",
    "with open(train_annotation_path, 'w') as f:\n",
    "    json.dump(train_coco, f, indent=4)\n",
    "\n",
    "with open(val_annotation_path, 'w') as f:\n",
    "    json.dump(val_coco, f, indent=4)\n",
    "    \n",
    "with open(test_annotation_path, 'w') as f:\n",
    "    json.dump(test_coco, f, indent=4)\n",
    "    \n",
    "# CONFIG = dict(**substep_params)\n",
    "# CONFIG[\"train_coco_annotation\"] = \"train_coco_annotations.json\"\n",
    "# CONFIG[\"val_coco_annotation\"] = \"val_coco_annotations.json\"\n",
    "# CONFIG[\"test_coco_annotation\"] = \"test_coco_annotations.json\"\n",
    "# CONFIG[\"train_images\"] = \"train_data\"\n",
    "# CONFIG[\"val_images\"] = \"eval_data\"\n",
    "# CONFIG[\"test_images\"] = \"test_data\"\n",
    "# TODO:\n",
    "# CONFIG[\"CLASSES\"] = CLASSES\n",
    "\n",
    "# config_path = osp.join(tmp_entities.dataset_config, \"config.json\")\n",
    "# with open(config_path, 'w') as f:\n",
    "#     json.dump(CONFIG, f, indent=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90687e97-db34-493a-b087-184f62fc2a34",
   "metadata": {},
   "source": [
    "### Archiving train, validation and test coco datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305aec9c-b4ae-4f15-bba2-65577c70d189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save tmp_entities (train_data,eval_data,test_data) to outputs of step data_prep\n",
    "from sinara.store import SinaraStore\n",
    "\n",
    "outputs = substep.outputs()\n",
    "\n",
    "SinaraStore.archive_tmp_files_to_store(tmp_dir=tmp_entities.train_data, store_path=outputs.train_data)\n",
    "SinaraStore.archive_tmp_files_to_store(tmp_dir=tmp_entities.eval_data, store_path=outputs.eval_data)\n",
    "SinaraStore.archive_tmp_files_to_store(tmp_dir=tmp_entities.test_data, store_path=outputs.test_data)\n",
    "#SinaraStore.archive_tmp_files_to_store(tmp_dir=tmp_entities.dataset_config, store_path=outputs.dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dab20-5483-485e-b734-3042135d48d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
